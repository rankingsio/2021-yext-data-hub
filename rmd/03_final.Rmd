---
title: "Yext Search Data Hub"
author: |
  | Lead: Chris Dreyer ([rankings.io](https://rankings.io/))
  | Support: François Delavy & Daniel Kupka ([frontpagedata.com](https://frontpagedata.com/))
date: "Last updated on `r Sys.Date()`"
output:
  html_document:
    theme: paper
    highlight: kate
    # code_folding: hide
    toc: true
    toc_depth: 3
    toc_float: true
    number_sections: true
    keep_md: true # keep the intermediary files, including the plots as .png
editor_options:
  chunk_output_type: console
---


<style>
.list-group-item.active, .list-group-item.active:hover, .list-group-item.active:focus {
background-color: #D21D5C;
border-color: #D21D5C;
}

body {
font-family: 'Alegreya Sans', sans-serif;
color: #333333;
font-size: 18px;
}

h1 {
font-weight: bold;
font-size: 28px;
}

h1.title {
font-size: 30px;
color: #111111;
}

h2 {
font-size: 24px;
}

h3 {
font-size: 18px;
}
</style>


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE, fig.showtext = TRUE,
                      # dev = "svg",
                      dpi = 720,
                      # fig.retina = 2,
                      fig.align = "center",
                      fig.width = 5,
                      fig.height = 4)
knitr::knit_hooks$set(inline = function(x) {
  prettyNum(x, big.mark = ",", small.mark = ",", scientific = F)
})

required_packages <- c("tidyverse", "here", "patchwork", "ggtext") #, "colorspace", "pdftools", "kableExtra", "ggrepel", "ggiraph", "lubridate", "htmlwidgets")

for(i in required_packages) { 
  if(!require(i, character.only = T)) {
    
    #  if package is not existing, install then load the package
    install.packages(i, dependencies = T)
    require(i, character.only = T)
  }
}


# Theme: 

base_size = 10
r_col <- "#D21D5C" ## highlight color of rankings.io

my_theme <- function(){
  theme_minimal() +
    theme(
      plot.margin = margin(10, 10, 10, 10),
      plot.background = element_rect(color = "white",
                                     fill = "white"),
      plot.title = element_text(size = 1.2 * base_size),
      plot.title.position = "plot",
      plot.subtitle = element_text(size = base_size),
      plot.caption = element_text(color = "grey40",
                                  size = 0.9 * base_size),
      plot.caption.position = "plot",
      strip.text = element_text(size =  base_size,
                                face = "bold"),
      axis.line.x = element_line(color = "black",
                                 size = .5),
      axis.line.y = element_line(color = "black",
                                 size = .5),
      axis.title.x = element_text(size =  base_size,
                                  face = "bold"),
      axis.title.y = element_text(size = base_size,
                                  face = "bold"),
      axis.text = element_text(size = 0.9 * base_size,
                               color = "black", #face = "bold"
      ),
      # axis.ticks = element_blank(),
      axis.ticks = element_line(color = "black"),
      panel.grid.major.x = element_line(size = .4,
                                        color = "#eaeaea",
                                        linetype = "solid"),
      panel.grid.major.y = element_line(size = .4,
                                        color = "#eaeaea",
                                        linetype = "solid"),
      panel.grid.minor.x = element_blank(), #element_line(size = .4, color = "#eaeaea", linetype = "solid"),
      panel.grid.minor.y = element_blank(),
      panel.spacing.x = unit(2, "lines"),
      panel.spacing.y = unit(1, "lines")
    )
}


## numeric format for labels
num_format <- scales::format_format(big.mark = ",", small.mark = ",", scientific = F)

```


```{r data, include=FALSE}

# LOAD DATA sent by Yext:
yext_data <- rio::import(here::here("proc_data", "yext_data.rds"))


# we append new values to the Yext Data
# these are the values of the last 2 months absent from the data sent by Yext.
# these were collected manually online.
new_Longtail_Imps_and_Clicks <- tibble(
  `Month of Date1` = c("September", "October"),
  `Year of Date1` = c(2021, 2021),
  `Avg. Longtail Clicks Per Loc` = c(3.9, 4),
  `Avg. Longtail Impressions Per Loc` = c(92, 100),
  char_date = c("September 2021", "October 2021"),
  date = lubridate::as_date(c("2021-09-01", "2021-10-01"), format = "%Y-%m-%d")
)
yext_data$Longtail_Imps_and_Clicks <- yext_data$Longtail_Imps_and_Clicks %>% 
  rbind(new_Longtail_Imps_and_Clicks)

# Google Maps Views, Google search views
new_Google_Maps_and_Search_Views <- tibble(
  `Month of Date1` = c("September", "October"),
  `Year of Date1` = c(2021, 2021),
  `Avg. Google Maps Views Per Loc` = c(1751, 1631),
  `Avg. Google Search Views Per Loc` = c(1733.7, 1496.7),
  char_date = c("September 2021", "October 2021"),
  date = lubridate::as_date(c("2021-09-01", "2021-10-01"), format = "%Y-%m-%d")
)
yext_data$G_MVs <- yext_data$G_MVs %>%
  rbind(new_Google_Maps_and_Search_Views)

# Google Driving Directions -> G_DDs
new_Google_Driving_Directions <- tibble(
  `Month of Date1` = c("September", "October"),
  `Year of Date1` = c(2021, 2021),
  `Avg. Google Driving Directions Per Loc` = c(21.2, 20),
  char_date = c("September 2021", "October 2021"),
  date = lubridate::as_date(c("2021-09-01", "2021-10-01"), format = "%Y-%m-%d")
)
yext_data$G_DDs <- yext_data$G_DDs %>% 
  rbind(new_Google_Driving_Directions)

# phone calls, website clicks -> G_PCs
new_Google_phonecalls_and_websiteclicks <- tibble(
  `Month of Date1` = c("September", "October"),
  `Year of Date1` = c(2021, 2021),
  `Avg. Google Phone Calls Per Loc` = c(30, 27),
  `Avg. Google Website Clicks Per Loc` = c(36.6, 41.2),
  char_date = c("September 2021", "October 2021"),
  date = lubridate::as_date(c("2021-09-01", "2021-10-01"), format = "%Y-%m-%d")
)
yext_data$G_PCs <- yext_data$G_PCs %>% 
  rbind(new_Google_phonecalls_and_websiteclicks)


# load data collected online for key comparisons:
# these are the data about all industries:

extend_network_listings_all_industries <- rio::import(here::here(
  "proc_data",
  "Search_Network_Listings-all_verticals-USA-(2021-11-14).csv")
) %>%
  mutate(date = lubridate::as_date(date, format = "%d.%m.%Y"))

google_maps_and_search_views_all_industries <- rio::import(here::here(
  "proc_data",
  "Google Listings Impressions (2011-11-17).csv")
) %>%
  mutate(date = lubridate::as_date(date, format = "%d.%m.%Y"))

google_diving_directions_all_industries <- rio::import(here::here(
  "proc_data",
  "driving_directions(2021-11-17).csv")
) %>%
  mutate(date = lubridate::as_date(date, format = "%d.%m.%Y"))

google_phone_and_website_all_industries <- rio::import(here::here(
  "proc_data",
  "phone_calls-and_website_clicks (2021-11-17).csv")
) %>%
  mutate(date = lubridate::as_date(date, format = "%d.%m.%Y"))


```



# Introduction 

Yext, a company that provides enterprise search solutions based on natural language processing and artificial intelligence, publishes anonymized data on its [Search Data Hub](https://www.yext.com/search-data-hub).. The data it contains are samples of listing and local page data across a variety of search engines and other digital endpoints collected by Yext from its clients. Yext enables the exploration of insights into consumer behavior trends, including shifts in search volume and foot traffic trends by industry.  

We analyzed the data for the legal services industry. What can we learn from the Yext Search Data Hub that is relevant for personal injury lawyers? We present our key findings here.


# Methodology
Yext kindly provided us with a subset of the data from its Search Data Hub—data about legal services (subvertical) from U.S. companies. We enriched these data with some key spot comparisons observed directly on the online [Search Data Hub](https://www.yext.com/search-data-hub).  

## About the Data

Yext mentions that “the data is comprised of a sample of listing and local page data across a variety of search engines, and other digital endpoints. Insights are shown only on a region and industry level where there are sufficient businesses, locations, and search engine data sources to maintain anonymity and privacy for Yext customers and where Yext customers have adopted the platform for a sufficient period of time to provide a meaningful comparison year over year. As data may vary between regions due to, among other things, the sample size or availability of data for certain businesses and subverticals, industry insights may not be comparable across regions.”   
The data published by Yext and presented in this analysis are best compared over time. However, because the metrics are averages over a sample, we can still compare the absolute values of the _legal services_ to the values of the rest of the industry.

**Sample sizes:**  

* Sample Size for the "subvertical" of _legal services_ in the United States: 5,409 businesses including 7,249 entities.   
* Sample Size for the whole United States, all industries (all subverticals): 73,909 businesses including 545,974 entities   


# Research Findings 

## Extended Network Impressions and Clicks

_Impressions_ represent the number of times a sample of listings appeared in search results across Google Maps, Google Search, Bing, Facebook, and the broader network, and clicks is the number of times they were clicked.    

```{r fig.width=8}

Impressions <- yext_data$Longtail_Imps_and_Clicks %>% 
  ggplot(aes(x = date, y = `Avg. Longtail Impressions Per Loc`)) +
  geom_line() + 
  labs(title = "Average Extended Network Impressions\nFor Longtail Keywords",
       subtitle = "Industry: Legal Services, Geography: U.S.",
       caption = "") +
  xlab("") +
  ylab("") +
  my_theme() +
  scale_x_date(date_labels = "%b-%y", date_breaks  ="6 month")


Clicks <- yext_data$Longtail_Imps_and_Clicks %>% 
  ggplot(aes(x = date, y = `Avg. Longtail Clicks Per Loc` )) +
  geom_line() + 
  labs(title = "Average Extended Network Clicks\nFor Longtail Keywords",
       subtitle = "Industry: Legal Services, Geography: U.S.",
       caption = "") +
  xlab("") +
  ylab("") +
  my_theme() +
  scale_x_date(date_labels = "%b-%y", date_breaks  ="6 month")


Impressions + Clicks

# yext_data$Longtail_Imps_and_Clicks %>% 
#   select(date, `Avg. Longtail Impressions Per Loc`, `Avg. Longtail Clicks Per Loc` ) %>%
#   pivot_longer(cols = c(`Avg. Longtail Impressions Per Loc`, `Avg. Longtail Clicks Per Loc`), 
#                names_to = "measure", values_to = "values")


# Some Statistics:

rcor <- cor(yext_data$Longtail_Imps_and_Clicks$`Avg. Longtail Impressions Per Loc`, yext_data$Longtail_Imps_and_Clicks$`Avg. Longtail Clicks Per Loc`)

```

There was a sudden increase in the _average Extended network clicks_ since summer 2021.  

Visually, there does not seem to be a strong positive correlation between _impressions_ and _clicks._ This is reflected in the Pearson correlation coefficient, which is $r = `r round(rcor, 2)`$. This coefficient ranges from 0, indicating that there is no linear correlation between clicks and impressions, to 1, indicating that there is a perfect correlation between impressions and clicks. There is a small correlation between the number of impressions and clicks, meaning that clicks is not completely independent of impressions. However, this relation is very far from being perfect and an increase in impressions is not necessarily, directly, and completely reflected in the number of clicks.  

### Click-Through Rate

Because Yext shared data about both impressions and clicks, we can compute the average _click-through rate_ (CTR): $CTR = clicks / impressions$. 

```{r , out.width="500px"}

yext_data$Longtail_Imps_and_Clicks %>% 
  ggplot(aes(x = date, y = `Avg. Longtail Clicks Per Loc`/`Avg. Longtail Impressions Per Loc` )) +
  geom_line() + 
  labs(title = "Average Extended Network CTR\nFor Longtail Keywords",
       subtitle = "Industry: Legal Services, Geography: U.S.",
       caption = "") +
  xlab("") +
  ylab("") +
  scale_y_continuous(labels = scales::label_percent()) +
  my_theme() +
  scale_x_date(date_labels = "%b-%y", date_breaks  ="6 month")

CTR_legalservices = yext_data$Longtail_Imps_and_Clicks %>% 
  mutate(ctr = `Avg. Longtail Clicks Per Loc`/`Avg. Longtail Impressions Per Loc`) %>%
  summarise(mean_ctr = mean(ctr))
```

The average CTR in _legal services_ for longtail keywords in the extended network (Google Maps, Google Search, Bing, Facebook, and the broader network) is of `r round(CTR_legalservices*100, 2)`%.  

### Industry Comparison

We compare the numbers of extended network impressions and clicks in the legal services sector to the same averaged metrics for all industries. By doing so, we compare the performance of legal services listings to the global average.  

```{r fig.width=8}

Longtail_Imps_and_Clicks_all_data <- yext_data$Longtail_Imps_and_Clicks %>%
  select(date, impressions = `Avg. Longtail Impressions Per Loc`, clicks = `Avg. Longtail Clicks Per Loc`) %>%
  mutate(source = "legal_services") %>%
  rbind(extend_network_listings_all_industries) %>%
  pivot_longer(cols = c(impressions, clicks), names_to = "metric", values_to = "value")

Impressions <- Longtail_Imps_and_Clicks_all_data %>% 
  filter(metric == "impressions") %>%
  ggplot(aes(x = date, y = value, color = source)) +
  geom_line() + 
  labs(title = "Average Extended Network Impressions\nFor Longtail Keywords",
       subtitle = "Geography: U.S.",
       caption = "") +
  scale_color_manual(values = c(r_col, "black")) +
  xlab("") +
  ylab("") +
  my_theme() +
  annotate("text", x = lubridate::as_date("2019-10-01"), y = 100, label = "Legal Services") +
  annotate("text", x = lubridate::as_date("2020-01-01"), y = 230, label = "All Industries", color = r_col) +
  theme(legend.position = "none") +
  scale_x_date(date_labels = "%b-%y", date_breaks  ="6 month")


Clicks <- Longtail_Imps_and_Clicks_all_data %>% 
  filter(metric == "clicks") %>%
  ggplot(aes(x = date, y = value, color = source)) +
  geom_line() + 
  labs(title = "Average Extended Network Clicks\nFor Longtail Keywords",
       subtitle = "Geography: U.S.",
       caption = "") +
  scale_color_manual(values = c(r_col, "black")) +
  xlab("") +
  ylab("") +
  my_theme()  +
  annotate("text", x = lubridate::as_date("2019-08-01"), y = 3, label = "Legal Services") +
  annotate("text", x = lubridate::as_date("2020-01-01"), y = 22, label = "All Industries", color = r_col) +
  theme(legend.position = "none") +
  scale_x_date(date_labels = "%b-%y", date_breaks  ="6 month")


Impressions + Clicks

# correlation btw Impressions and Clicks for All_Industry
rcor_allindustry <- cor(
  Longtail_Imps_and_Clicks_all_data %>% filter(source == "all_verticals", metric == "impressions") %>% .$value, 
  Longtail_Imps_and_Clicks_all_data %>% filter(source == "all_verticals", metric == "clicks") %>% .$value)

# some basic stats:
avg_impressions_allindustry = Longtail_Imps_and_Clicks_all_data %>% 
  filter(source == "all_verticals", metric == "impressions") %>%
  .$value %>%
  mean()
avg_clicks_allindustry = Longtail_Imps_and_Clicks_all_data %>% 
  filter(source == "all_verticals", metric == "clicks") %>%
  .$value %>%
  mean()
avg_impressions_legalservices = Longtail_Imps_and_Clicks_all_data %>% 
  filter(source == "legal_services", metric == "impressions") %>%
  .$value %>%
  mean()
avg_clicks_legalservices = Longtail_Imps_and_Clicks_all_data %>% 
  filter(source == "legal_services", metric == "clicks") %>%
  .$value %>%
  mean()
CTR_allindustry = Longtail_Imps_and_Clicks_all_data %>% 
  filter(source == "all_verticals") %>%
  pivot_wider(names_from = metric) %>%
  mutate(ctr = clicks / impressions) %>%
  summarise(mean_ctr = mean(ctr))

```

When measured across all industries, there is a much larger correlation between impressions and clicks: the Pearson correlation coefficient is $r = `r round(rcor_allindustry, 2)`$. This means that fluctuations in impressions are well reflected in clicks, albeit not perfectly (perfectly would mean r = 1).    

The _average extended network impressions for longtail keywords_ for _all industries together_ is `r round(avg_impressions_allindustry/avg_impressions_legalservices, 1)` times larger than for _legal services_. The gap is even larger for the _Clicks_: it is `r round(avg_clicks_allindustry/avg_clicks_legalservices, 1)` times larger for _all industries together_ than for _legal services_. This suggests that, in this sample, _legal services_ generally have less success in turning impressions into clicks. This is reflected in the CTR. The CTR of all industries together is on average of `r round(CTR_allindustry*100, 2)`%, much higher than the average CTR for the _legal services_, `r round(CTR_legalservices*100, 2)`%.  

```{r CTR_comparison, fig.width=7, out.width="700px"}

# comparison of CTR for legal services to industry average.
CTR_data_for_plot <- Longtail_Imps_and_Clicks_all_data %>% 
  pivot_wider(names_from = "metric", values_from = "value") %>% 
  mutate(CTR = clicks/impressions)

CTR_data_for_plot %>% 
  ggplot(aes(x = date, y = CTR, color = source )) +
  geom_line() + 
  labs(title = "Average Extended Network CTR For Longtail Keywords",
       subtitle = "Geography: U.S.",
       caption = "Data: Yext, Presentation: Rankings.io") +
  xlab("") +
  ylab("CTR") +
  scale_y_continuous(labels = scales::label_percent()) +
  my_theme() +
  theme(legend.position = "none") +
  scale_x_date(date_labels = "%b-%y", date_breaks  ="6 month") +
  scale_color_manual(values = c(r_col, "black")) +
  geom_hline(yintercept = 0.0876, color = r_col, size = 0.8, linetype = "dashed") +
  geom_hline(yintercept = 0.0262, color = "black", size = 0.8, linetype = "dashed") +
  annotate(geom = "richtext", 
           label = "The CTR of the average of <b><span style='color: #D21D5C';'>all industries</span></b> (8.8%) <br>
           is more than <b>3 times larger</b><br>
           than the average CTR of the <b><span style='color: black;'>legal services</span></b> (2.6%).",
           color = "grey40",
           size = 3.8,
           x = lubridate::ymd(20200501), 
           y = 0.05,
           label.size = NA) +
  annotate("segment", x = lubridate::ymd(20190501), xend = lubridate::ymd(20190501), y = 0.0262, yend = 0.0876, 
           colour = "grey40", size=0.8, arrow=arrow(ends = "both", length = unit(3, "mm")))


# CTR_data_for_plot %>% group_by(source) %>% summarise(mean_CTR = mean(CTR))

```

We can index the values measured for the _legal services_ sector and _all industries_ to the value of 100% in January 2019. By doing so, we can precisely compare their trends and determine whether the values for the legal services follow the same fluctuations as those for all industries.    

```{r fig.width=8}

Impressions <- Longtail_Imps_and_Clicks_all_data %>% 
  filter(metric == "impressions") %>%
  group_by(source) %>%
  mutate(indexed_value = value/value[which.min(date)]) %>% # indexing to first date by source
  ggplot(aes(x = date, y = indexed_value, color = source)) +
  geom_line() + 
  labs(title = "Average Extended Network Impressions\nFor Longtail Keywords",
       subtitle = "Geography: U.S., values indexed to Jan. 2019",
       caption = "") +
  scale_color_manual(values = c(r_col, "black")) +
  xlab("") +
  ylab("") +
  my_theme() +
  annotate("text", x = lubridate::as_date("2020-10-10"), y = 0.6, label = "Legal Services") +
  annotate("text", x = lubridate::as_date("2020-01-01"), y = 1.1, label = "All Industries", color = r_col) +
  theme(legend.position = "none") +
  scale_x_date(date_labels = "%b-%y", date_breaks  ="6 month") +
  scale_y_continuous(labels = scales::percent)


Clicks <- Longtail_Imps_and_Clicks_all_data %>% 
  filter(metric == "clicks") %>%
  group_by(source) %>%
  mutate(indexed_value = value/value[which.min(date)]) %>% # indexing to first date by source
  ggplot(aes(x = date, y = indexed_value, color = source)) +
  geom_line() + 
  labs(title = "Average Extended Network Clicks\nFor Longtail Keywords",
       subtitle = "Geography: U.S., values indexed to Jan. 2019",
       caption = "") +
  scale_color_manual(values = c(r_col, "black")) +
  xlab("") +
  ylab("") +
  my_theme()  +
  annotate("text", x = lubridate::as_date("2019-10-01"), y = 0.8, label = "Legal Services") +
  annotate("text", x = lubridate::as_date("2020-01-01"), y = 1.5, label = "All Industries", color = r_col) +
  theme(legend.position = "none") +
  scale_x_date(date_labels = "%b-%y", date_breaks  ="6 month") +
  scale_y_continuous(labels = scales::percent)


Impressions + Clicks

rcor_legalVSindustry_impressions <- cor(
  Longtail_Imps_and_Clicks_all_data %>% filter(source == "legal_services", metric == "impressions") %>% .$value, 
  Longtail_Imps_and_Clicks_all_data %>% filter(source == "all_verticals", metric == "impressions") %>% .$value)
rcor_legalVSindustry_clicks <- cor(
  Longtail_Imps_and_Clicks_all_data %>% filter(source == "legal_services", metric == "clicks") %>% .$value, 
  Longtail_Imps_and_Clicks_all_data %>% filter(source == "all_verticals", metric == "clicks") %>% .$value)

```

We can see that the _clicks_ in the _legal services_ seem to follow the general trends well. This is reflected in the Pearson correlation coefficient: $r = `r round(rcor_legalVSindustry_clicks, 2)`$. However, this is does not seem to be the case for the _impressions_. The _impressions_ in the _legal services_ sector do not visually follow the general trends well and there is no correlation: $r = `r round(rcor_legalVSindustry_impressions, 2)`$. Could this be because the impressions do not depend from the general presence or behavior of users whereas the clicks do?   


## Google My Business

This chapter focuses on the Google ecosystem.   

### Impressions

The _average Google Maps views per location_ represents the number of times a listing was viewed on a Google Map. The _average Google Search views per location_ represents the number of times a listing was viewed on Google Search. Google Map views and Google Search views together represent the total number of impressions listings receive across the Google ecosystem.  

```{r, fig.width=8}

maps <- yext_data$G_MVs %>% 
  ggplot(aes(x = date, y = `Avg. Google Maps Views Per Loc` )) +
  geom_line() +
  labs(title = "Average Google Maps Views Per Location",
       subtitle = "Industry: Legal Services, Geography: U.S.") +
  xlab("") +
  ylab("") +
  my_theme() +
  scale_x_date(date_labels = "%b-%y", date_breaks  ="6 month") +
  geom_vline(xintercept = lubridate::ymd(20200313), color = "grey80", size = 0.8, linetype = "dashed") +
  geom_label(aes(x = lubridate::ymd(20201101), y = 2300, label = "COVID-19 declared\nnational emergency"),
             nudge_x = 0, size = 3.5, color = "grey80", label.size = 0) +
  annotate("segment", x = lubridate::ymd(20200110), xend = lubridate::ymd(20200310), y = 2113, yend = 558, 
           colour = r_col, size=0.8, arrow=arrow(length = unit(3, "mm"))) +
  geom_label(aes(x = lubridate::ymd(20200310), y = 1600, label = "-75% btw. Feb.\nand April 2020"),
             nudge_x = 170, size = 3.5, color = r_col, label.size = 0)

searches <- yext_data$G_MVs %>% 
  ggplot(aes(x = date, y = `Avg. Google Search Views Per Loc` )) +
  geom_line() + 
  labs(title = "Average Google Search Views Per Location",
       subtitle = "Industry: Legal Services, Geography: U.S.") +
  xlab("") +
  ylab("") +
  my_theme() +
  scale_x_date(date_labels = "%b-%y", date_breaks  ="6 month") +
  geom_vline(xintercept = lubridate::ymd(20200313), color = "grey80", size = 0.8, linetype = "dashed") +
  geom_label(aes(x = lubridate::ymd(20201101), y = 1700, label = "COVID-19 declared\nnational emergency"),
             nudge_x = 0, size = 3.5, color = "grey80", label.size = 0) +
  geom_label(aes(x = lubridate::ymd(20200610), y = 1400, label = "+40% btw. June 2020\nand Oct. 2021"),
             nudge_x = 0, size = 3.5, color = r_col, label.size = 0) +
  annotate("segment", x = lubridate::ymd(20200601), xend = lubridate::ymd(20211001), y = 1164, yend = 1596, 
           colour = r_col, size=0.8, arrow=arrow(length = unit(3, "mm")))

maps + searches

```


The _Average Google Maps Views Per Location_ decreased by 73.6% between February and April 2020, at the beginning of the COVID pandemic, and is slowly recovering.   

The _Average Google Search Views Per Location_ is growing steadily since mid-2020. It has never been so high.   

We note the importance of a presence on Google Maps for companies active in _legal services_ as the average number of maps views is larger than the average number of search views.  

#### Industry Comparison

We compare the Google Maps and Search Views from the _legal services_ to the same metrics for _all the industries_. By doing so, we compare the performance of listings in the _legal services_ to the global average.   

```{r Google_Mapsandsearch_Views, fig.width=8, fig.height=4.5}

# the data: 
google_maps_and_search_views_all_data <- yext_data$G_MVs %>%
  select(date, map_views = `Avg. Google Maps Views Per Loc`, search_views = `Avg. Google Search Views Per Loc`) %>%
  mutate(source = "legal_services") %>%
  rbind(google_maps_and_search_views_all_industries) %>%
  pivot_longer(cols = c(map_views, search_views), names_to = "metric", values_to = "value")

# some basic stats:
avg_map_views_allindustry = google_maps_and_search_views_all_data %>% 
  filter(source == "all_verticals", metric == "map_views") %>%
  .$value %>%
  mean()
avg_search_views_allindustry = google_maps_and_search_views_all_data %>% 
  filter(source == "all_verticals", metric == "search_views") %>%
  .$value %>%
  mean()
avg_map_views_legalservices = google_maps_and_search_views_all_data %>% 
  filter(source == "legal_services", metric == "map_views") %>%
  .$value %>%
  mean()
avg_search_views_legalservices = google_maps_and_search_views_all_data %>% 
  filter(source == "legal_services", metric == "search_views") %>%
  .$value %>%
  mean()


# the plots:
Map_Views <- google_maps_and_search_views_all_data %>% 
  filter(metric == "map_views") %>%
  ggplot(aes(x = date, y = value, color = source)) +
  geom_line() + 
  labs(title = "Average Google Maps Views\nPer Location",
       subtitle = "Geography: U.S.",
       caption = "") +
  scale_color_manual(values = c(r_col, "black")) +
  xlab("") +
  ylab("Views (log scale)") +
  my_theme() +
  annotate("text", x = lubridate::as_date("2019-08-01"), y = 3000, label = "Legal Services") +
  annotate("text", x = lubridate::as_date("2020-09-01"), y = 22000, label = "All Industries", color = r_col) +
  theme(legend.position = "none") + 
  scale_y_log10() +
  scale_x_date(date_labels = "%b-%y", date_breaks  ="6 month") +
  geom_hline(yintercept = avg_map_views_allindustry, color = r_col, size = 0.8, linetype = "dashed") +
  geom_hline(yintercept = avg_map_views_legalservices, color = "black", size = 0.8, linetype = "dashed") +
  annotate("segment", x = lubridate::ymd(20200801), xend = lubridate::ymd(20200801), 
           y = avg_map_views_legalservices, yend = avg_map_views_allindustry, 
           colour = "grey40", size=0.8, arrow=arrow(ends = "last", length = unit(3, "mm")))  +
  annotate(geom = "richtext", 
           label = "<b>x11</b>",
           color = "grey40",
           size = 4,
           x = lubridate::ymd(20201101), 
           y = 4000,
           label.size = NA) 

Search_Views <- google_maps_and_search_views_all_data %>% 
  filter(metric == "search_views") %>%
  ggplot(aes(x = date, y = value, color = source)) +
  geom_line() + 
  labs(title = "Average Google Search Views\nPer Location",
       subtitle = "",
       caption = "Data: Yext, Presentation: Rankings.io") +
  scale_color_manual(values = c(r_col, "black")) +
  xlab("") +
  ylab("") +
  my_theme() +
  # annotate("text", x = lubridate::as_date("2019-10-01"), y = 1300, label = "Legal Services") +
  # annotate("text", x = lubridate::as_date("2019-09-01"), y = 9000, label = "All Industries", color = r_col) +
  theme(legend.position = "none") + 
  scale_y_log10() + 
  scale_x_date(date_labels = "%b-%y", date_breaks  ="6 month") +
  geom_hline(yintercept = avg_search_views_allindustry, color = r_col, size = 0.8, linetype = "dashed") +
  geom_hline(yintercept = avg_search_views_legalservices, color = "black", size = 0.8, linetype = "dashed")  +
  annotate("segment", x = lubridate::ymd(20190501), xend = lubridate::ymd(20190501), 
           y = avg_search_views_legalservices, yend = avg_search_views_allindustry, 
           colour = "grey40", size=0.8, arrow=arrow(ends = "last", length = unit(3, "mm"))) +
  annotate(geom = "richtext", 
           label = "<b>x7</b>",
           color = "grey40",
           size = 4,
           x = lubridate::ymd(20190801), 
           y = 3000,
           label.size = NA) +
  annotate(geom = "richtext", 
           label = "The average of<br>
           <b><span style='color: #D21D5C';'>all industries</span></b><br>
           is <b>7 times larger</b><br>
           than the average of<br>
           the <b><span style='color: black;'>legal services</span></b>",
           color = "grey40",
           size = 3.8,
           x = lubridate::ymd(20200801), 
           y = 3000,
           label.size = NA)

Map_Views + Search_Views



```

The trends in the _legal services_ follow the trends of the global average of all industries very well. With one notable difference, the average of Google Maps Views and Google Search Views per location is much smaller than the global average. The average of Google Maps Views in the _legal services_ is on average only `r round(avg_map_views_legalservices/avg_map_views_allindustry *100, 1)`% of the global average. The average of Google Search Views in the _legal services_ is on average only `r round(avg_search_views_legalservices/avg_search_views_allindustry *100, 1)`% of the global average. Note the logarithmic scale on the y-axis. It is used because it allows for a better comparison of the trends despite the difference in magnitude.  

```{r, fig.width=8, fig.height=4.5, include=FALSE}

Map_Views <- google_maps_and_search_views_all_data %>% 
  filter(metric == "map_views") %>% 
  group_by(source) %>%
  mutate(indexed_value = value/value[which.min(date)]) %>% # indexing to first date by source
  ggplot(aes(x = date, y = indexed_value, color = source)) +
  geom_line() + 
  labs(title = "Average Google Maps Views\nPer Location",
       subtitle = "Geography: U.S., values indexed to Jan. 2019",
       caption = "") +
  scale_color_manual(values = c(r_col, "black")) +
  xlab("") +
  ylab("") +
  my_theme() +
  annotate("text", x = lubridate::as_date("2019-08-01"), y = 0.45, label = "Legal Services") +
  annotate("text", x = lubridate::as_date("2020-09-01"), y = 1.6, label = "All Industries", color = r_col) +
  theme(legend.position = "none") + 
  scale_x_date(date_labels = "%b-%y", date_breaks  ="6 month") +
  scale_y_continuous(labels = scales::percent)

Search_Views <- google_maps_and_search_views_all_data %>% 
  filter(metric == "search_views") %>%
  group_by(source) %>%
  mutate(indexed_value = value/value[which.min(date)]) %>% # indexing to first date by source
  ggplot(aes(x = date, y = indexed_value, color = source)) +
  geom_line() + 
  labs(title = "Average Google Search Views\nPer Location",
       subtitle = "Geography: U.S., values indexed to Jan. 2019",
       caption = "Data: Yext, Presentation: Rankings.io") +
  scale_color_manual(values = c(r_col, "black")) +
  xlab("") +
  ylab("") +
  my_theme() +
  annotate("text", x = lubridate::as_date("2019-10-01"), y = 0.8, label = "Legal Services") +
  annotate("text", x = lubridate::as_date("2019-09-01"), y = 1.2, label = "All Industries", color = r_col) +
  theme(legend.position = "none") + 
  scale_x_date(date_labels = "%b-%y", date_breaks  ="6 month") +
  scale_y_continuous(labels = scales::percent)

Map_Views + Search_Views


# correlations:  
rcor_legalVSindustry_maps <- cor(
  google_maps_and_search_views_all_data %>% filter(source == "legal_services", metric == "map_views") %>% .$value, 
  google_maps_and_search_views_all_data %>% filter(source == "all_verticals", metric == "map_views") %>% .$value)
rcor_legalVSindustry_search <- cor(
  google_maps_and_search_views_all_data %>% filter(source == "legal_services", metric == "search_views") %>% .$value, 
  google_maps_and_search_views_all_data %>% filter(source == "all_verticals", metric == "search_views") %>% .$value)

```


### Clicks

#### Google Phone Calls

The _Average Google Phone Calls Per Location_ represents the number of times a user clicked on the phone call link from a Google listing. There was a clear dip of around -30% at the onset of the COVID pandemic. This metric has reached the maximum level again since.    

```{r , out.width="500px"}

yext_data$G_PCs %>%
  ggplot(aes(x = date, y = `Avg. Google Phone Calls Per Loc` )) +
  geom_line() +
  labs(title = "Average Google Phone Calls Per Location",
       caption = "Industry: Legal Services, Geography: U.S.") +
  xlab("") +
  ylab("") +
  my_theme() +
  scale_x_date(date_labels = "%b-%y", date_breaks  ="6 month") +
  geom_vline(xintercept = lubridate::ymd(20200313), color = "grey80", size = 0.8, linetype = "dashed") +
  geom_label(aes(x = lubridate::ymd(20200901), y = 31.5, label = "COVID-19 declared\nnational emergency"),
             nudge_x = 0, size = 3.5, color = "grey80", label.size = 0)  +
  annotate("segment", x = lubridate::ymd(20200110), xend = lubridate::ymd(20200310), y = 28.31770, yend = 18.93106, 
           colour = r_col, size=0.8, arrow=arrow(length = unit(3, "mm"))) +
  geom_label(aes(x = lubridate::ymd(20190901), y = 22, label = "-30% btw. Feb.\nand April 2020"),
             nudge_x = 0, size = 3.5, color = r_col, label.size = 0)

```


#### Google Website Clicks

The _Average Google Website Clicks Per Location_ represents the number of times a consumer clicked through to the corporate domain from a location page. It seems that there was a small dip at the onset of the COVID pandemic, but it is less clear.     

```{r , out.width="500px"}
yext_data$G_PCs %>%
  ggplot(aes(x = date, y = `Avg. Google Website Clicks Per Loc` )) +
  geom_line() +
  labs(title = "Average Google Website Clicks Per Location",
       caption = "Industry: Legal Services, Geography: U.S.") +
  xlab("") +
  ylab("") +
  my_theme() +
  scale_x_date(date_labels = "%b-%y", date_breaks  ="6 month") +
  geom_vline(xintercept = lubridate::ymd(20200313), color = "grey80", size = 0.8, linetype = "dashed") +
  geom_label(aes(x = lubridate::ymd(20200901), y = 41.5, label = "COVID-19 declared\nnational emergency"),
             nudge_x = 0, size = 3.5, color = "grey80", label.size = 0) 
```


#### Google Driving Directions

The _Average Google Driving Directions Per Location_ represents the number of times a consumer clicked to get driving directions from the location pages. This metric was clearly affected by the COVID pandemic. It dropped by 80% between February and April 2020. It is slowly recovering, now reaching about 80% of the pre-pandemic level.      

```{r , out.width="500px"}
yext_data$G_DDs %>% 
  ggplot(aes(x = date, y = `Avg. Google Driving Directions Per Loc` )) +
  geom_line() +
  labs(title = "Average Google Driving Directions Per Location",
       caption = "Industry: Legal Services, Geography: U.S.") +
  xlab("") +
  ylab("") +
  my_theme() +
  scale_x_date(date_labels = "%b-%y", date_breaks  ="6 month") +
  geom_vline(xintercept = lubridate::ymd(20200313), color = "grey80", size = 0.8, linetype = "dashed") +
  geom_label(aes(x = lubridate::ymd(20200901), y = 25, label = "COVID-19 declared\nnational emergency"),
             nudge_x = 0, size = 3.5, color = "grey80", label.size = 0) +
  annotate("segment", x = lubridate::ymd(20200110), xend = lubridate::ymd(20200310), y = 24.510778, yend = 4.505001, 
           colour = r_col, size=0.8, arrow=arrow(length = unit(3, "mm"))) +
  geom_label(aes(x = lubridate::ymd(20190901), y = 11, label = "-80% btw. Feb.\nand April 2020"),
             nudge_x = 0, size = 3.5, color = r_col, label.size = 0)
```



#### Industry Comparison

```{r Google_Clicks, fig.width=9}

# the data for the plots and stats:
google_phone_and_website_all_data <- yext_data$G_PCs %>%
  select(date, phone_calls = `Avg. Google Phone Calls Per Loc`, website_clicks = `Avg. Google Website Clicks Per Loc`) %>%
  mutate(source = "legal_services") %>%
  rbind(google_phone_and_website_all_industries)

google_driving_all_data <- yext_data$G_DDs %>%
  select(date, driving_directions = `Avg. Google Driving Directions Per Loc`) %>%
  mutate(source = "legal_services") %>%
  rbind(google_diving_directions_all_industries)

google_clicks_all_data <- google_phone_and_website_all_data %>% 
  left_join(google_driving_all_data) %>%
  pivot_longer(cols = c(phone_calls, website_clicks, driving_directions), names_to = "metric", values_to = "value")


# some basic stats:
avg_phone_call_all <- google_clicks_all_data %>%
  filter(metric == "phone_calls", source == "all_verticals") %>%
  summarise(avg = mean(value)) %>%
  .$avg
avg_phone_call_legal <- google_clicks_all_data %>%
  filter(metric == "phone_calls", source == "legal_services") %>%
  summarise(avg = mean(value)) %>%
  .$avg
avg_website_clicks_all <- google_clicks_all_data %>%
  filter(metric == "website_clicks", source == "all_verticals") %>%
  summarise(avg = mean(value)) %>%
  .$avg
avg_website_clicks_legal <- google_clicks_all_data %>%
  filter(metric == "website_clicks", source == "legal_services") %>%
  summarise(avg = mean(value)) %>%
  .$avg
avg_driving_directions_all <- google_clicks_all_data %>%
  filter(metric == "driving_directions", source == "all_verticals") %>%
  summarise(avg = mean(value)) %>%
  .$avg
avg_driving_directions_legal <- google_clicks_all_data %>%
  filter(metric == "driving_directions", source == "legal_services") %>%
  summarise(avg = mean(value)) %>%
  .$avg


# the plots
Phone_Calls <- google_clicks_all_data %>%
  filter(metric == "phone_calls") %>%
  ggplot(aes(x = date, y = value, color = source)) +
  geom_line() + 
  labs(title = "Average Google Phone Calls\nPer Location",
       subtitle = "Geography: U.S.",
       caption = "") +
  scale_color_manual(values = c(r_col, "black")) +
  xlab("") +
  ylab("(log scale)") +
  my_theme() +
  annotate("text", x = lubridate::as_date("2019-08-01"), y = 35, label = "Legal Services") +
  annotate("text", x = lubridate::as_date("2019-08-01"), y = 190, label = "All Industries", color = r_col) +
  theme(legend.position = "none", plot.margin = margin(5, 5, 5, 5)) +  
  scale_y_log10() + 
  geom_hline(yintercept = avg_phone_call_all, color = r_col, size = 0.8, linetype = "dashed") +
  geom_hline(yintercept = avg_phone_call_legal, color = "black", size = 0.8, linetype = "dashed") +
  annotate("segment", x = lubridate::ymd(20201001), xend = lubridate::ymd(20201001), 
           y = avg_phone_call_legal, yend = avg_phone_call_all, 
           colour = "grey40", size=0.8, arrow=arrow(ends = "last", length = unit(3, "mm"))) +
  annotate(geom = "richtext", 
           label = "<b>x6</b>",
           color = "grey40",
           size = 4,
           x = lubridate::ymd(20210101), 
           y = 75,
           label.size = NA) 


Website_Clicks <- google_clicks_all_data %>%
  filter(metric == "website_clicks") %>%
  ggplot(aes(x = date, y = value, color = source)) +
  geom_line() + 
  labs(title = "Average Google Website Clicks\nPer Location",
       subtitle = "",
       caption = "") +
  scale_color_manual(values = c(r_col, "black")) +
  xlab("") +
  ylab("") +
  my_theme() +
  # annotate("text", x = lubridate::as_date("2020-10-01"), y = 70, label = "Legal Services") +
  # annotate("text", x = lubridate::as_date("2019-11-01"), y = 340, label = "All Industries", color = r_col) +
  theme(legend.position = "none", plot.margin = margin(5, 5, 5, 5)) +  
  scale_y_log10()  + 
  geom_hline(yintercept = avg_website_clicks_all, color = r_col, size = 0.8, linetype = "dashed") +
  geom_hline(yintercept = avg_website_clicks_legal, color = "black", size = 0.8, linetype = "dashed") +
  annotate("segment", x = lubridate::ymd(20190601), xend = lubridate::ymd(20190601), 
           y = avg_website_clicks_legal, yend = avg_website_clicks_all, 
           colour = "grey40", size=0.8, arrow=arrow(ends = "last", length = unit(3, "mm"))) +
  annotate(geom = "richtext", 
           label = "<b>x9</b>",
           color = "grey40",
           size = 4,
           x = lubridate::ymd(20190901), 
           y = 100,
           label.size = NA) +
  annotate(geom = "richtext", 
           label = "The average of<br>
           <b><span style='color: #D21D5C';'>all industries</span></b><br>
           is <b>9 times larger</b><br>
           than the average of<br>
           the <b><span style='color: black;'>legal services</span></b>",
           color = "grey40",
           size = 3.8,
           x = lubridate::ymd(20201001), 
           y = 100,
           label.size = NA)


Driving_Directions <- google_clicks_all_data %>%
  filter(metric == "driving_directions") %>%
  ggplot(aes(x = date, y = value, color = source)) +
  geom_line() + 
  labs(title = "Average Google Driving Directions\nPer Location",
       subtitle = "",
       caption = "Data: Yext, Presentation: Rankings.io") +
  scale_color_manual(values = c(r_col, "black")) +
  xlab("") +
  ylab("") +
  my_theme() +
  # annotate("text", x = lubridate::as_date("2019-08-01"), y = 60, label = "Legal Services") +
  # annotate("text", x = lubridate::as_date("2020-07-01"), y = 300, label = "All Industries", color = r_col) +
  theme(legend.position = "none", plot.margin = margin(5, 5, 5, 5)) +  
  scale_y_log10()  + 
  geom_hline(yintercept = avg_driving_directions_all, color = r_col, size = 0.8, linetype = "dashed") +
  geom_hline(yintercept = avg_driving_directions_legal, color = "black", size = 0.8, linetype = "dashed") +
  annotate("segment", x = lubridate::ymd(20201101), xend = lubridate::ymd(20201101), 
           y = avg_driving_directions_legal, yend = avg_driving_directions_all, 
           colour = "grey40", size=0.8, arrow=arrow(ends = "last", length = unit(3, "mm"))) +
  annotate(geom = "richtext", 
           label = "<b>x14</b>",
           color = "grey40",
           size = 4,
           x = lubridate::ymd(20210201), 
           y = 70,
           label.size = NA)


Phone_Calls + Website_Clicks + Driving_Directions





```

On the contrary to the _legal services_, we do not see a gap at the onset of the COVID pandemic for the average of all industries. The _Average Google Phone Calls Per Location_ for the _legal services_ is only `r round(avg_phone_call_legal/avg_phone_call_all*100,1)`% of the global average.   

The _Average Google Website Clicks Per Location_ for the _legal services_ is fluctuating similarly to the average of all industries. The _Average Google Website Clicks Per Location_ for the _legal services_ is only `r round(avg_website_clicks_legal/avg_website_clicks_all*100,1)`% of the global average.    

The _Average Google Driving Directions Per Location_ for the _legal services_ is behaving similarly to the average of all industries. The recovery after the onset of the pandemic is similar, albeit a bit slower. This might reflect the fact that _legal services_ can more easily be managed remotely than other industries. The _Average Google Driving Directions Per Location_ for the _legal services_ is only `r round(avg_driving_directions_legal/avg_driving_directions_all*100,1)`% of the global average.  

# Summary and Main Findings

## The Impact of COVID

The COVID did not have an impact on all metrics shared by Yext. But it had a clear impact on Google Maps Views and Google Driving Directions; they dropped significantly (-75% and -80%). They almost reached their pre-pandemic level again, probably illustrating a near-total recovery of in-person business for legal services.   

Did COVID have a lasting effect on some metrics? Google Search Views are increasing constantly since mid-2020. Regardless of if this effect is due to an increased online presence of clients due to COVID, it is a good time to optimize Google Search Clicks and take advantage of this fact. 

## Legal Services Perform Worse Than the Average

On all metrics provided by Yext, legal services performed only 10% to 30% of the industry's average value. For instance, the number of impressions for longtail keywords for the legal services are only 37% of the same metric for the average of all industries.   

| Metric      | Percentage of Industry Average  |
| :------------ |:-------------| 
| Average Extended Network Impressions for Longtail Keywords     | 37% | 
| Average Extended Network Clicks for Longtail Keywords    | 10.8%      |  
| Average Extended Network CTR for Longtail Keywords | 29.9%     | 
| Average Google Maps Views Per Location | 8.7%      | 
| Average Google Search Views Per Location | 14.7%      | 
| Average Google Phone Calls Per Location | 16.6%      | 
| Average Google Website Clicks Per Location | 10.9%      | 
| Average Google Driving Directions Per Location  | 7%      | 

This "underperformance" could simply be due to the fact that legal services is not as in-demand as the average of all industries. Still, CTR, for instance, is not directly demand dependant. It seems that legal services have the possiblity to improve their longtail keyword CTR.   

## Imperfect Correlation Between Impressions and Clicks

There is not a perfect correlation between the _Average Extended Network Impressions_ and _Average Extended Network Clicks_ for longtail keywords. We could expect that when impressions increase, clicks directly follow. This works quite well when looking at the average of the whole industry, the Pearson correlation coefficient (r) is 0.82 (no correlation is 0 and perfect correlation is 1). Fluctuations in the impressions are well reflected in the clicks, albeit not perfectly.  

However, this is not the case for the legal services, the Pearson correlation coefficient (r) is only 0.21. It is unclear why fluctuations in the impressions are less well reflected in the clicks for legal services. It could be an artifact due to the smaller samples size, but Yext is publishing data about 5,409 businesses active in the legal services. That is a quite large sample already.  





